from datetime import datetime
from typing import Any
from typing import Dict
from typing import List
from typing import Optional

from pydantic import BaseModel
from pydantic import model_validator

from enmedd.chat.models import RetrievalDocs
from enmedd.configs.constants import DocumentSource
from enmedd.configs.constants import MessageType
from enmedd.configs.constants import SearchFeedbackType
from enmedd.db.enums import ChatSessionSharedStatus
from enmedd.file_store.models import FileDescriptor
from enmedd.llm.override_models import LLMOverride
from enmedd.llm.override_models import PromptOverride
from enmedd.search.models import BaseFilters
from enmedd.search.models import ChunkContext
from enmedd.search.models import RetrievalDetails
from enmedd.search.models import SearchDoc
from enmedd.search.models import Tag
from enmedd.server.models import MinimalTeamspaceSnapshot
from enmedd.tools.models import ToolCallFinalResult


class SourceTag(Tag):
    source: DocumentSource


class TagResponse(BaseModel):
    tags: List[SourceTag]


class SimpleQueryRequest(BaseModel):
    query: str


class UpdateChatSessionThreadRequest(BaseModel):
    # If not specified, use enMedD AI default assistant
    chat_session_id: int
    new_alternate_model: str


class ChatSessionCreationRequest(BaseModel):
    # If not specified, use enMedD AI default assistant
    assistant_id: int = 0
    description: Optional[str] = None
    teamspace_id: Optional[int] = None


class HelperResponse(BaseModel):
    values: Dict[str, str]
    details: Optional[List[str]] = None


class CreateChatSessionID(BaseModel):
    chat_session_id: int


class ChatFeedbackRequest(BaseModel):
    chat_message_id: int
    is_positive: Optional[bool] = None
    feedback_text: Optional[str] = None
    predefined_feedback: Optional[str] = None

    @model_validator(mode="before")
    def check_is_positive_or_feedback_text(cls, values: Dict) -> Dict:
        is_positive = values.get("is_positive")
        feedback_text = values.get("feedback_text")

        if is_positive is None and feedback_text is None:
            raise ValueError("Empty feedback received.")

        return values


"""
Currently the different branches are generated by changing the search query

                 [Empty Root Message]  This allows the first message to be branched as well
              /           |           \
[First Message] [First Message Edit 1] [First Message Edit 2]
       |                  |
[Second Message]  [Second Message of Edit 1 Branch]
"""


class CreateChatMessageRequest(ChunkContext):
    """Before creating messages, be sure to create a chat_session and get an id"""

    chat_session_id: int
    # This is the primary-key (unique identifier) for the previous message of the tree
    parent_message_id: Optional[int] = None
    # New message contents
    message: str
    # file's that we should attach to this message
    file_descriptors: List[FileDescriptor]
    # If no prompt provided, uses the largest prompt of the chat session
    # but really this should be explicitly specified, only in the simplified APIs is this inferred
    # Use prompt_id 0 to use the system default prompt which is Answer-Question
    prompt_id: Optional[int] = None
    # If search_doc_ids provided, then retrieval options are unused
    search_doc_ids: Optional[List[int]] = None
    retrieval_options: Optional[RetrievalDetails] = None
    # allows the caller to specify the exact search query they want to use
    # will disable Query Rewording if specified
    query_override: Optional[str] = None

    # allows the caller to override the Assistant / Prompt
    llm_override: Optional[LLMOverride] = None
    prompt_override: Optional[PromptOverride] = None

    # allow user to specify an alternate assistant
    alternate_assistant_id: Optional[int] = None

    # used for seeded chats to kick off the generation of an AI answer
    use_existing_user_message: bool = False

    @model_validator(mode="before")
    def check_search_doc_ids_or_retrieval_options(cls, values: Dict) -> Dict:
        search_doc_ids = values.get("search_doc_ids")
        retrieval_options = values.get("retrieval_options")

        if search_doc_ids is None and retrieval_options is None:
            raise ValueError(
                "Either search_doc_ids or retrieval_options must be provided, but not both or neither."
            )

        return values


class ChatMessageIdentifier(BaseModel):
    message_id: int


class ChatRenameRequest(BaseModel):
    chat_session_id: int
    name: Optional[str] = None


class ChatSessionUpdateRequest(BaseModel):
    sharing_status: ChatSessionSharedStatus


class RenameChatSessionResponse(BaseModel):
    new_name: str  # This is only really useful if the name is generated


class ChatSessionDetails(BaseModel):
    id: int
    name: str
    assistant_id: int
    time_created: str
    shared_status: ChatSessionSharedStatus
    folder_id: Optional[int] = None
    current_alternate_model: Optional[str] = None
    groups: Optional[List[MinimalTeamspaceSnapshot]] = None


class ChatSessionsResponse(BaseModel):
    sessions: List[ChatSessionDetails]


class SearchFeedbackRequest(BaseModel):
    message_id: int
    document_id: str
    document_rank: int
    click: bool
    search_feedback: Optional[SearchFeedbackType] = None

    @model_validator(mode="before")
    def check_click_or_search_feedback(cls, values: Dict) -> Dict:
        click = values.get("click")
        feedback = values.get("search_feedback")

        if click is False and feedback is None:
            raise ValueError("Empty feedback received.")

        return values


class ChatMessageDetail(BaseModel):
    message_id: int
    parent_message: int | None = None
    latest_child_message: int | None = None
    message: str
    rephrased_query: str | None = None
    context_docs: RetrievalDocs | None = None
    message_type: MessageType
    time_sent: datetime
    overridden_model: str | None
    alternate_assistant_id: int | None = None
    # Dict mapping citation number to db_doc_id
    chat_session_id: int | None = None
    citations: dict[int, int] | None = None
    files: list[FileDescriptor]
    tool_calls: list[ToolCallFinalResult]

    def model_dump(self, *args: list, **kwargs: dict[str, Any]) -> dict[str, Any]:  # type: ignore
        initial_dict = super().model_dump(mode="json", *args, **kwargs)  # type: ignore
        initial_dict["time_sent"] = self.time_sent.isoformat()
        return initial_dict


class ChatSessionDetailResponse(BaseModel):
    chat_session_id: int
    description: str
    assistant_id: int
    assistant_name: str
    messages: List[ChatMessageDetail]
    time_created: datetime
    shared_status: ChatSessionSharedStatus
    current_alternate_model: Optional[str] = None
    groups: List[MinimalTeamspaceSnapshot] | None


class QueryValidationResponse(BaseModel):
    reasoning: str
    answerable: bool


class AdminSearchRequest(BaseModel):
    query: str
    filters: BaseFilters


class AdminSearchResponse(BaseModel):
    documents: List[SearchDoc]


# TODO: replace the name here
class EnmeddAnswer(BaseModel):
    answer: Optional[str] = None
